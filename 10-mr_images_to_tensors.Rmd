---
title: "Convert Images to Tensors"
date: "17.11.2020"
output: github_document
---

*NOTE:* Use these functions `ANTsRNet::resampleTensor`, `reticulate::array_reshape`

```{r, include = FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/10_images_to_tensors-",
  out.width = "100%"
)

`%>%` <- purrr::`%>%`

library(tidyverse, warn.conflicts = FALSE)
library(ANTsRCore)

library(devtools)
library(fs)

library(rraysplot)
# source("R/plot_array2d.R")
# source("R/images_info.R")
```


## Image data for U-Net

Source [2.2.11 Data representations for neural networks](https://livebook.manning.com/book/deep-learning-with-r/chapter-2/48)
in [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r) by
François Chollet with J. J. Allaire.

Images typically have three dimensions:
```
height × width × color channels
```
Although grayscale images have only a single color channel 
and could thus be stored in 2D tensors, by convention 
image tensors are always 3D, with a one-dimensional color channel
for grayscale images. 

A batch of 80 grayscale images of size 768×384 could thus
be stored in a tensor of shape 
```
(80, 768, 384, 1)
```
and a batch of 80 color images could be stored in a tensor of shape
```
(80, 768, 384, 3)
```
and a batch of 80 mask --
```
(80, 768, 384, 2)
```


## Important Note

We will crop all images to 768x384 and prepare additional data with resampled (smaller)
images: 384x192 and 192x96. Note that both dimensions 768x384 are divisble by 128
(768/2^7=6, 384/2^7=3).


## Read Images Info

```{r, rows.print=8}
info <- images_info("../80_images", extension = "dcm") %>% 
  dplyr::slice(1:8)
info
```

```{r}
crop_image_768x384x1 <- function(img, ll = c(34, 56), wh = c(768, 384)) {
  ll = c(ll, 1)                        # c(34, 56, 1)
  ur = ll + c(wh, 0) - c(1, 1, 0)      # c(768 - 1, 384 - 1, 0)
  ANTsRCore::cropIndices(img, ll, ur)
}

crop_image_768x384 <- function(img, ll = c(34, 56), wh = c(768, 384)) {
  ur = ll + wh - c(1, 1)               # c(768 - 1, 384 - 1)
  ANTsRCore::cropIndices(img, ll, ur)
}
```


## Base images

```{r}
base_paths <- info %>% filter(kind == "MRI")
iList <- imageFileNames2ImageList(base_paths[["file_path"]])
n_images <- length(iList)

Y_train <- array(
  data = NA, 
  dim = c(3, 768, 384, n_images)
)
```


```{r}
p <- info$file_path[[1]]
img <- ANTsRCore::antsImageRead(p)
channels <- ANTsRCore::splitChannels(img)
slice <- ANTsRCore::extractSlice(channels[[1]], 1, 3)
cslice <- crop_image_768x384(slice)
aslice = as.array(cslice)

dim(cslice)
dim(aslice)
```

```{r, figures2-side1, fig.show="hold", fig.asp=0.5, out.width="48%"}
plot_array2d(aslice)
invisible(plot(cslice, doCropping=F))
```

```{r}
K <- keras::backend()
array_crop <- purrr::compose(as.array, crop_image_768x384x1)
aList <- map(iList, array_crop)
str(aList)
seq_along(aList)

for (i in seq_along(aList)) {
  Y_train[,,,i] <- aList[[i]]
}
Y_train <- as.array(
  K$permute_dimensions(Y_train, pattern = c(3L, 1L, 2L, 0L))
)

str(Y_train)

dimnames(Y_train)[[1]] <- base_paths$patient
dimnames(Y_train)[[1]]
```

```{r}
dim(Y_train)
dimnames(Y_train)[[1]]
dim(Y_train[2,,,1])
dim(Y_train["1023660",,,1])
```

```{r, figures2-side2, fig.show="hold", fig.asp=0.5, out.width="48%"}
plot_array2d(Y_train[2,,,1])
plot_array2d(Y_train["1023660",,,1])
```
